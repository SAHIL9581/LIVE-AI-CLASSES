{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNI/mELzOoIH1RAZEFVW18q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAHIL9581/LIVE-AI-CLASSES/blob/main/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O3YMEbPfZWgn",
        "outputId": "f94d2a77-b543-4ab3-a837-aa3c0a9dc1c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torch 2.5.1+cu118\n",
            "Uninstalling torch-2.5.1+cu118:\n",
            "  Successfully uninstalled torch-2.5.1+cu118\n",
            "Files removed: 26\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.86)\n",
            "Collecting triton==3.2.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.5.1%2Bcu118-cp311-cp311-linux_x86_64.whl (838.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m838.4/838.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.5.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.5.1+cu118\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "44f6bb087266420396f6f68cf8f8f60d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.16.0\n",
            "  Downloading torchtext-0.16.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (2.32.3)\n",
            "Collecting torch==2.1.0 (from torchtext==0.16.0)\n",
            "  Downloading torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (1.26.4)\n",
            "Requirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (12.1.105)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Downloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.0->torchtext==0.16.0) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->torchtext==0.16.0) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0->torchtext==0.16.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0->torchtext==0.16.0) (1.3.0)\n",
            "Downloading torchtext-0.16.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, torch, torchtext\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu118\n",
            "    Uninstalling torch-2.5.1+cu118:\n",
            "      Successfully uninstalled torch-2.5.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.1.0 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.1.0 torchtext-0.16.0 triton-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "torchtext"
                ]
              },
              "id": "189a5886824047008b6ea0f7d6c4d33e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "!pip uninstall torchtext torch -y\n",
        "!pip cache purge  # Clear cached packages to avoid conflicts\n",
        "\n",
        "# Install PyTorch for CUDA 11.8 (modify if using a different CUDA version)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install the compatible torchtext version\n",
        "!pip install torchtext==0.16.0  # Make sure it matches the PyTorch version\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "# Download stopwords if not already present\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Replace 'your_file.zip' with the name of your uploaded zip file\n",
        "zip_file = \"/content/blogs.zip\"\n",
        "\n",
        "# Create a directory for extraction\n",
        "extract_dir = \"/content/extracted_folder\"\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(f\"Files extracted to {extract_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWWIgVnvn7IW",
        "outputId": "d05b915f-3cf3-4800-a07c-f5e1bdd1621a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to /content/extracted_folder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "# Folder containing XML files\n",
        "folder_path = \"/content/extracted_folder/blogs\"  # Change to your actual folder path\n",
        "\n",
        "# List to store extracted data\n",
        "all_data = []\n",
        "error_files = []\n",
        "\n",
        "# Loop through all XML files\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".xml\"):  # Process only XML files\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        try:\n",
        "            # Extract metadata from filename\n",
        "            parts = filename.split('.')\n",
        "            if len(parts) < 3:\n",
        "                continue  # Skip invalid files\n",
        "\n",
        "            author_id, gender, age = parts[0], parts[1], int(parts[2])\n",
        "\n",
        "            # Read XML file with error handling\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                xml_content = f.read()\n",
        "\n",
        "            # Parse XML\n",
        "            tree = ET.ElementTree(ET.fromstring(xml_content))\n",
        "            root = tree.getroot()\n",
        "\n",
        "            # Extract blog posts\n",
        "            for post in root.findall(\"post\"):\n",
        "                text = post.text.strip() if post.text else \"\"  # Extract text\n",
        "                all_data.append([author_id, gender, age, text])\n",
        "\n",
        "        except Exception as e:\n",
        "            error_files.append((filename, str(e)))  # Store error details\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(all_data, columns=[\"Author_ID\", \"Gender\", \"Age\", \"Text\"])\n",
        "\n",
        "# Save extracted data\n",
        "csv_path = \"blog_data.csv\"\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Data extraction complete. Saved to {csv_path}.\")\n",
        "print(f\"Skipped {len(error_files)} files due to errors.\")\n",
        "\n",
        "# Log files that caused errors\n",
        "if error_files:\n",
        "    error_log_path = \"error_files.log\"\n",
        "    with open(error_log_path, \"w\") as f:\n",
        "        for file, error in error_files:\n",
        "            f.write(f\"{file}: {error}\\n\")\n",
        "    print(f\"Error log saved to {error_log_path}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA0AqUHjqDed",
        "outputId": "3d36c9a7-3e88-4502-808c-edfb4d95b8f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data extraction complete. Saved to blog_data.csv.\n",
            "Skipped 11449 files due to errors.\n",
            "Error log saved to error_files.log.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== STEP 1: LOAD & PREPROCESS DATA ====================\n",
        "\n",
        "# Load dataset\n",
        "csv_path = \"blog_data.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Text cleaning function\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r'\\W+', ' ', text)  # Remove special characters\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    tokens = word_tokenize(text)  # Tokenize\n",
        "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Remove stopwords\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df[\"Cleaned_Text\"] = df[\"Text\"].astype(str).apply(clean_text)\n",
        "\n",
        "# Save cleaned data\n",
        "cleaned_csv_path = \"cleaned_blog_data.csv\"\n",
        "df.to_csv(cleaned_csv_path, index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "3xvRHduVZ-jO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== STEP 2: TOKENIZATION & EMBEDDINGS ====================\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "df[\"Tokenized_Text\"] = df[\"Cleaned_Text\"].astype(str).apply(tokenizer)\n",
        "\n",
        "# Build vocabulary\n",
        "counter = Counter()\n",
        "for tokens in df[\"Tokenized_Text\"]:\n",
        "    counter.update(tokens)\n",
        "\n",
        "# Create vocabulary (min frequency = 2)\n",
        "vocab_obj = vocab(counter, min_freq=2, specials=[\"<unk>\", \"<pad>\"])\n",
        "vocab_obj.set_default_index(vocab_obj[\"<unk>\"])\n",
        "\n",
        "# Convert text to numerical format\n",
        "df[\"Numerical_Text\"] = df[\"Tokenized_Text\"].apply(lambda x: [vocab_obj[word] for word in x])\n",
        "\n",
        "# Padding function\n",
        "MAX_LEN = 100  # Adjust based on dataset\n",
        "def pad_sequence(seq, max_len=MAX_LEN):\n",
        "    if len(seq) < max_len:\n",
        "        seq += [vocab_obj[\"<pad>\"]] * (max_len - len(seq))  # Pad\n",
        "    return seq[:max_len]  # Truncate\n",
        "\n",
        "df[\"Padded_Text\"] = df[\"Numerical_Text\"].apply(lambda x: pad_sequence(x))\n",
        "\n",
        "# Save processed data\n",
        "processed_csv_path = \"tokenized_blog_data.csv\"\n",
        "df.to_csv(processed_csv_path, index=False)\n"
      ],
      "metadata": {
        "id": "VoNUhY8uad00"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== STEP 3: CREATE DATASET & DATALOADER ====================\n",
        "\n",
        "class BlogDataset(Dataset):\n",
        "    def __init__(self, dataframe, indices): # Add indices argument\n",
        "        self.data = dataframe\n",
        "        self.indices = indices # Store indices\n",
        "        self.gender_map = {\"male\": 0, \"female\": 1}  # Binary classification\n",
        "        self.age_map = {10: 0, 20: 1, 30: 2, 40: 3, 50: 4}  # Age groups\n",
        "        self.topic_map = {i: i for i in range(10)}  # Example: 10 topics\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices) # Use length of indices\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Use indices to access data from the original dataframe\n",
        "        data_idx = self.indices[idx]\n",
        "        text = torch.tensor(self.data.iloc[data_idx][\"Padded_Text\"], dtype=torch.long)\n",
        "        gender = torch.tensor(self.gender_map[self.data.iloc[data_idx][\"Gender\"]], dtype=torch.long)\n",
        "        age = torch.tensor(self.age_map[min(self.data.iloc[data_idx][\"Age\"] // 10 * 10, 50)], dtype=torch.long)  # Bucket ages\n",
        "        topic = torch.tensor(self.topic_map[self.data.iloc[data_idx][\"Author_ID\"] % 10], dtype=torch.long)  # Example topic\n",
        "        return text, gender, age, topic\n",
        "\n",
        "# Split dataset\n",
        "train_size = int(0.8 * len(df))\n",
        "val_size = len(df) - train_size\n",
        "train_data, val_data = torch.utils.data.random_split(df, [train_size, val_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "# Pass indices to BlogDataset\n",
        "train_dataset = BlogDataset(df, train_data.indices) # Pass original dataframe and indices\n",
        "val_dataset = BlogDataset(df, val_data.indices)  # Pass original dataframe and indices\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n"
      ],
      "metadata": {
        "id": "snpsXuwIamZJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== STEP 4: BUILD MULTI-TASK CNN MODEL ====================\n",
        "\n",
        "class MultiTaskCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_filters, filter_sizes, hidden_dim, output_dims, dropout=0.5):\n",
        "        super(MultiTaskCNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.convs = nn.ModuleList([nn.Conv1d(embed_dim, num_filters, k) for k in filter_sizes])\n",
        "        self.fc_gender = nn.Linear(num_filters * len(filter_sizes), output_dims[\"gender\"])\n",
        "        self.fc_age = nn.Linear(num_filters * len(filter_sizes), output_dims[\"age\"])\n",
        "        self.fc_topic = nn.Linear(num_filters * len(filter_sizes), output_dims[\"topic\"])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        conv_results = [F.relu(conv(x)).max(dim=2)[0] for conv in self.convs]\n",
        "        x = torch.cat(conv_results, dim=1)\n",
        "        x = self.dropout(x)\n",
        "        return self.fc_gender(x), self.fc_age(x), self.fc_topic(x)\n",
        "\n",
        "# Initialize Model\n",
        "vocab_size = len(vocab_obj)\n",
        "embed_dim = 100\n",
        "num_filters = 128\n",
        "filter_sizes = [3, 4, 5]\n",
        "hidden_dim = 256\n",
        "output_dims = {\"gender\": 2, \"age\": 5, \"topic\": 10}\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = MultiTaskCNN(vocab_size, embed_dim, num_filters, filter_sizes, hidden_dim, output_dims).to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKZF9ghpam-9",
        "outputId": "639815f7-809f-49ae-f4d6-0cdffabaa40e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiTaskCNN(\n",
            "  (embedding): Embedding(94983, 100)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(100, 128, kernel_size=(3,), stride=(1,))\n",
            "    (1): Conv1d(100, 128, kernel_size=(4,), stride=(1,))\n",
            "    (2): Conv1d(100, 128, kernel_size=(5,), stride=(1,))\n",
            "  )\n",
            "  (fc_gender): Linear(in_features=384, out_features=2, bias=True)\n",
            "  (fc_age): Linear(in_features=384, out_features=5, bias=True)\n",
            "  (fc_topic): Linear(in_features=384, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== STEP 5: TRAINING & EVALUATION ====================\n",
        "\n",
        "# Loss functions & Optimizer\n",
        "criterion_gender = nn.CrossEntropyLoss()\n",
        "criterion_age = nn.CrossEntropyLoss()\n",
        "criterion_topic = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss, total_correct_gender, total_correct_age, total_correct_topic = 0, 0, 0, 0\n",
        "    for texts, gender_labels, age_labels, topic_labels in train_loader:\n",
        "        texts, gender_labels, age_labels, topic_labels = texts.to(device), gender_labels.to(device), age_labels.to(device), topic_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        gender_out, age_out, topic_out = model(texts)\n",
        "\n",
        "        loss_gender = criterion_gender(gender_out, gender_labels)\n",
        "        loss_age = criterion_age(age_out, age_labels)\n",
        "        loss_topic = criterion_topic(topic_out, topic_labels)\n",
        "        loss = loss_gender + loss_age + loss_topic\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_correct_gender += (gender_out.argmax(1) == gender_labels).sum().item()\n",
        "        total_correct_age += (age_out.argmax(1) == age_labels).sum().item()\n",
        "        total_correct_topic += (topic_out.argmax(1) == topic_labels).sum().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}, Gender Acc: {total_correct_gender/len(train_dataset):.4f}, Age Acc: {total_correct_age/len(train_dataset):.4f}, Topic Acc: {total_correct_topic/len(train_dataset):.4f}\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"multi_task_cnn.pth\")\n",
        "print(\"Model training complete. Model saved!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWou6LK1apAe",
        "outputId": "22dc3aaa-be7f-4326-dbc5-82ec7b39357e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 4.1409, Gender Acc: 0.5604, Age Acc: 0.5409, Topic Acc: 0.1083\n",
            "Epoch 2/5, Loss: 3.9433, Gender Acc: 0.5949, Age Acc: 0.6118, Topic Acc: 0.1183\n",
            "Epoch 3/5, Loss: 3.8128, Gender Acc: 0.6389, Age Acc: 0.6540, Topic Acc: 0.1260\n",
            "Epoch 4/5, Loss: 3.6666, Gender Acc: 0.6872, Age Acc: 0.6897, Topic Acc: 0.1435\n",
            "Epoch 5/5, Loss: 3.5217, Gender Acc: 0.7236, Age Acc: 0.7188, Topic Acc: 0.1631\n",
            "Model training complete. Model saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "model.load_state_dict(torch.load(\"multi_task_cnn.pth\"))\n",
        "model.to(device)\n",
        "model.eval()  # Set to evaluation mode\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, dataloader):\n",
        "    total_loss, total_correct_gender, total_correct_age, total_correct_topic = 0, 0, 0, 0\n",
        "    criterion_gender = nn.CrossEntropyLoss()\n",
        "    criterion_age = nn.CrossEntropyLoss()\n",
        "    criterion_topic = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for texts, gender_labels, age_labels, topic_labels in dataloader:\n",
        "            texts, gender_labels, age_labels, topic_labels = texts.to(device), gender_labels.to(device), age_labels.to(device), topic_labels.to(device)\n",
        "\n",
        "            gender_out, age_out, topic_out = model(texts)\n",
        "\n",
        "            loss_gender = criterion_gender(gender_out, gender_labels)\n",
        "            loss_age = criterion_age(age_out, age_labels)\n",
        "            loss_topic = criterion_topic(topic_out, topic_labels)\n",
        "            loss = loss_gender + loss_age + loss_topic\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_correct_gender += (gender_out.argmax(1) == gender_labels).sum().item()\n",
        "            total_correct_age += (age_out.argmax(1) == age_labels).sum().item()\n",
        "            total_correct_topic += (topic_out.argmax(1) == topic_labels).sum().item()\n",
        "\n",
        "    print(f\"Validation Loss: {total_loss/len(dataloader):.4f}\")\n",
        "    print(f\"Gender Accuracy: {total_correct_gender/len(val_dataset):.4f}\")\n",
        "    print(f\"Age Accuracy: {total_correct_age/len(val_dataset):.4f}\")\n",
        "    print(f\"Topic Accuracy: {total_correct_topic/len(val_dataset):.4f}\")\n",
        "\n",
        "# Run evaluation\n",
        "evaluate_model(model, val_loader)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPXSSCGQarOJ",
        "outputId": "b780bd8a-57eb-4278-c4d3-108e6cc50ead"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.7642\n",
            "Gender Accuracy: 0.6758\n",
            "Age Accuracy: 0.6584\n",
            "Topic Accuracy: 0.1524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction function\n",
        "def predict_blog_post(model, text):\n",
        "    model.eval()\n",
        "    text = clean_text(text)  # Preprocess\n",
        "    tokens = tokenizer(text)  # Tokenize\n",
        "    numerical_text = [vocab_obj[word] for word in tokens]  # Convert to numerical\n",
        "    padded_text = pad_sequence(numerical_text)  # Pad sequence\n",
        "    input_tensor = torch.tensor(padded_text, dtype=torch.long).unsqueeze(0).to(device)  # Convert to tensor\n",
        "\n",
        "    with torch.no_grad():\n",
        "        gender_out, age_out, topic_out = model(input_tensor)\n",
        "\n",
        "    predicted_gender = \"Male\" if torch.argmax(gender_out) == 0 else \"Female\"\n",
        "    predicted_age = (torch.argmax(age_out).item() * 10, (torch.argmax(age_out).item() + 1) * 10)  # Age range\n",
        "    predicted_topic = torch.argmax(topic_out).item()\n",
        "\n",
        "    return predicted_gender, predicted_age, predicted_topic\n",
        "\n",
        "# Example Prediction\n",
        "sample_text = \"I love playing video games and watching sci-fi movies!\"\n",
        "pred_gender, pred_age, pred_topic = predict_blog_post(model, sample_text)\n",
        "\n",
        "print(f\"Predicted Gender: {pred_gender}\")\n",
        "print(f\"Predicted Age Group: {pred_age}\")\n",
        "print(f\"Predicted Topic ID: {pred_topic}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7RO-sJ2at1Q",
        "outputId": "6a2ef2b6-ab6c-42ad-dc07-e15c06ed2bdb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Gender: Male\n",
            "Predicted Age Group: (10, 20)\n",
            "Predicted Topic ID: 6\n"
          ]
        }
      ]
    }
  ]
}