{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMfd0PmzqNz1f96U7CWxcMq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAHIL9581/LIVE-AI-CLASSES/blob/main/Self_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch ## torch let's us create tensors and also provides helper functions\n",
        "import torch.nn as nn ## torch.nn gives us nn.module() and nn.Linear()\n",
        "import torch.nn.functional as F # This gives us the softmax()"
      ],
      "metadata": {
        "id": "7odpwBEi160-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model=2,\n",
        "                 row_dim=0,\n",
        "                 col_dim=1):\n",
        "        ## d_model = the number of embedding values per token.\n",
        "        ##           Because we want to be able to do the math by hand, we've\n",
        "        ##           the default value for d_model=2.\n",
        "        ##           However, in \"Attention Is All You Need\" d_model=512\n",
        "        ##\n",
        "        ## row_dim, col_dim = the indices we should use to access rows or columns\n",
        "\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        ## Initialize the Weights (W) that we'll use to create the\n",
        "        ## query (q), key (k) and value (v) for each token\n",
        "        ## NOTE: A lot of implementations include bias terms when\n",
        "        ##       creating the the queries, keys, and values, but\n",
        "        ##       the original manuscript that described Attention,\n",
        "        ##       \"Attention Is All You Need\" did not, so we won't either\n",
        "        self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "        self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "        self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "\n",
        "        self.row_dim = row_dim\n",
        "        self.col_dim = col_dim\n",
        "\n",
        "\n",
        "    def forward(self, token_encodings):\n",
        "        ## Create the query, key and values using the encoding numbers\n",
        "        ## associated with each token (token encodings)\n",
        "        q = self.W_q(token_encodings)\n",
        "        k = self.W_k(token_encodings)\n",
        "        v = self.W_v(token_encodings)\n",
        "\n",
        "        ## Compute similarities scores: (q * k^T)\n",
        "        sims = torch.matmul(q, k.transpose(dim0=self.row_dim, dim1=self.col_dim))\n",
        "\n",
        "        ## Scale the similarities by dividing by sqrt(k.col_dim)\n",
        "        scaled_sims = sims / torch.tensor(k.size(self.col_dim)**0.5)\n",
        "\n",
        "        ## Apply softmax to determine what percent of each tokens' value to\n",
        "        ## use in the final attention values.\n",
        "        attention_percents = F.softmax(scaled_sims, dim=self.col_dim)\n",
        "\n",
        "        ## Scale the values by their associated percentages and add them up.\n",
        "        attention_scores = torch.matmul(attention_percents, v)\n",
        "\n",
        "        return attention_scores\n"
      ],
      "metadata": {
        "id": "aA_cVSU22F4L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## create a matrix of token encodings...\n",
        "encodings_matrix = torch.tensor([[1.16, 0.23],\n",
        "                                 [0.57, 1.36],\n",
        "                                 [4.41, -2.16]])\n",
        "\n",
        "## set the seed for the random number generator\n",
        "torch.manual_seed(42)\n",
        "\n",
        "## create a basic self-attention ojbect\n",
        "selfAttention = SelfAttention(d_model=2,\n",
        "                               row_dim=0,\n",
        "                               col_dim=1)\n",
        "\n",
        "## calculate basic attention for the token encodings\n",
        "selfAttention(encodings_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goiONcct2O2u",
        "outputId": "c614f06e-061a-401d-c09a-92e236b8be75"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0100, 1.0641],\n",
              "        [0.2040, 0.7057],\n",
              "        [3.4989, 2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## print out the weight matrix that creates the queries\n",
        "selfAttention.W_q.weight.transpose(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-PGrcnV2Qxj",
        "outputId": "9f2f3c65-c442-418b-abd4-719775bf839b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5406, -0.1657],\n",
              "        [ 0.5869,  0.6496]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## print out the weight matrix that creates the keys\n",
        "selfAttention.W_k.weight.transpose(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSazOt9Q2TPL",
        "outputId": "d8d1a0ed-2e59-45b6-d02c-7ba8e163fedf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1549, -0.3443],\n",
              "        [ 0.1427,  0.4153]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## print out the weight matrix that creates the values\n",
        "selfAttention.W_v.weight.transpose(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFtSnPtx2Tcd",
        "outputId": "3c200d2a-81ee-447a-abbf-ef8c3c18927e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6233,  0.6146],\n",
              "        [-0.5188,  0.1323]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## calculate the queries\n",
        "selfAttention.W_q(encodings_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yv-h3gH2TjE",
        "outputId": "4611cd21-8bf6-4c05-9ef4-60dc55853fc8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7621, -0.0428],\n",
              "        [ 1.1063,  0.7890],\n",
              "        [ 1.1164, -2.1336]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## calculate the keys\n",
        "selfAttention.W_k(encodings_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEgeImdw2TmX",
        "outputId": "99995136-7ecb-49ea-a12d-3686f4a341a0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1469, -0.3038],\n",
              "        [ 0.1057,  0.3685],\n",
              "        [-0.9914, -2.4152]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## calculate the values\n",
        "selfAttention.W_v(encodings_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2DVvhEA2TpD",
        "outputId": "635de1c6-0ff8-4e81-f198-383f15d6991d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6038,  0.7434],\n",
              "        [-0.3502,  0.5303],\n",
              "        [ 3.8695,  2.4246]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = selfAttention.W_q(encodings_matrix)\n",
        "q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCLcu_NA2eNg",
        "outputId": "c13659c1-bb9f-4bd3-a22c-d9d3efb9cfb0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7621, -0.0428],\n",
              "        [ 1.1063,  0.7890],\n",
              "        [ 1.1164, -2.1336]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = selfAttention.W_k(encodings_matrix)\n",
        "k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fj0qiV12epW",
        "outputId": "54cce35e-b28a-41b4-929a-305eeca793bc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1469, -0.3038],\n",
              "        [ 0.1057,  0.3685],\n",
              "        [-0.9914, -2.4152]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sims = torch.matmul(q, k.transpose(dim0=0, dim1=1))\n",
        "sims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK_4gEf72eua",
        "outputId": "18c615fd-fe2f-4eb1-eb87-51d34af5b623"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0990,  0.0648, -0.6523],\n",
              "        [-0.4022,  0.4078, -3.0024],\n",
              "        [ 0.4842, -0.6683,  4.0461]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_sims = sims / (torch.tensor(2)**0.5)\n",
        "scaled_sims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlxQ0S-X2exE",
        "outputId": "e3551218-c42e-446f-927b-2ba2a92b6d28"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0700,  0.0458, -0.4612],\n",
              "        [-0.2844,  0.2883, -2.1230],\n",
              "        [ 0.3424, -0.4725,  2.8610]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_percents = F.softmax(scaled_sims, dim=1)\n",
        "attention_percents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7au-XeFi2ezm",
        "outputId": "98d50db6-0e5b-4d82-86f2-29776c751a77"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3573, 0.4011, 0.2416],\n",
              "        [0.3410, 0.6047, 0.0542],\n",
              "        [0.0722, 0.0320, 0.8959]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(attention_percents, selfAttention.W_v(encodings_matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qct1I_412e3B",
        "outputId": "eb3c1dc2-f799-4b50-87a4-090b53ce9355"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0100, 1.0641],\n",
              "        [0.2040, 0.7057],\n",
              "        [3.4989, 2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}